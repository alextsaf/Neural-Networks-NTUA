{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3η Εργασία: Βαθιά Μάθηση\n",
    "\n",
    "<span class=\"md-toc-item md-toc-h1\" role=\"listitem\" ref=\"n0\"><a href=\"#3η-εργασία-βαθιά-μάθηση\" class=\"md-toc-inner\">3η Εργασία: Βαθιά Μάθηση</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n3\"><a href=\"#image-captioning\" class=\"md-toc-inner\">Image Captioning</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n9\"><a href=\"#σύνολο-δεδομένων\" class=\"md-toc-inner\">Σύνολο δεδομένων</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h3\" role=\"listitem\" ref=\"n21\"><a href=\"#εποπτεία-των-δεδομένων\" class=\"md-toc-inner\">Εποπτεία των δεδομένων</a>\n",
    "<br><span class=\"md-toc-item md-toc-h3\" role=\"listitem\" ref=\"n31\"><a href=\"#κατέβασμα-του-συνόλου-δεδομένων\" class=\"md-toc-inner\">Κατέβασμα του συνόλου δεδομένων</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h3\" role=\"listitem\" ref=\"n42\"><a href=\"#google-drive-mount-προαιρετικό\" class=\"md-toc-inner\">Google Drive mount (προαιρετικό)</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n57\"><a href=\"#το-μοντέλο\" class=\"md-toc-inner\">Το μοντέλο</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n63\"><a href=\"#αξιολόγηση-της-ποιότητας-του-captioning-bleu\" class=\"md-toc-inner\">Αξιολόγηση της ποιότητας του captioning (BLEU)</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n74\"><a href=\"#βελτιώσεις-και-παραδοτέα\" class=\"md-toc-inner\">Βελτιώσεις (και παραδοτέα)</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h3\" role=\"listitem\" ref=\"n77\"><a href=\"#encoder\" class=\"md-toc-inner\">Encoder</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h3\" role=\"listitem\" ref=\"n81\"><a href=\"#προεπεξεργασία-κειμένου\" class=\"md-toc-inner\">Προεπεξεργασία κειμένου</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h3\" role=\"listitem\" ref=\"n89\"><a href=\"#embeddings\" class=\"md-toc-inner\">Embeddings</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h3\" role=\"listitem\" ref=\"n91\"><a href=\"#sentence-generator-beam-search\" class=\"md-toc-inner\">Sentence Generator (Beam Search)</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h3\" role=\"listitem\" ref=\"n97\"><a href=\"#υπερπαράμετροι-του-decoder\" class=\"md-toc-inner\">Υπερπαράμετροι του decoder</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n102\"><a href=\"#παραδοτέο\" class=\"md-toc-inner\">Παραδοτέο</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h1\" role=\"listitem\" ref=\"n105\"><a href=\"#διαγωνισμός-προαιρετικός\" class=\"md-toc-inner\">Διαγωνισμός (προαιρετικός)</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n107\"><a href=\"#εικόνες-διαγωνισμού\" class=\"md-toc-inner\">Εικόνες διαγωνισμού</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n111\"><a href=\"#δημιουργία-αρχείου-υποβολής\" class=\"md-toc-inner\">Δημιουργία αρχείου υποβολής</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n118\"><a href=\"#το-site-του-διαγωνισμού-στο-codalab\" class=\"md-toc-inner\">Το site του διαγωνισμού στο Codalab</a></span>\n",
    "<br><span class=\"md-toc-item md-toc-h2\" role=\"listitem\" ref=\"n122\"><a href=\"#υποβολή-απάντησης-και-leaderboard\" class=\"md-toc-inner\">Υποβολή απάντησης και leaderboard</a></span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Captioning\n",
    "\n",
    "Θέμα της 3ης εργασίας του μαθήματος είναι η Βαθιά Μάθηση. Θα μελετήσουμε\n",
    "ένα πρόβλημα που συνδυάζει Όραση Υπολογιστών και Επεξεργασία Φυσικής\n",
    "Γλώσσας. Συγκεκριμένα, θα φτιάξουμε ένα νευρωνικό δίκτυο παραγωγής\n",
    "λεκτικών περιγραφών από εικόνες (Image Captioning).\n",
    "\n",
    "Σημείο εκκίνησης θα είναι το επίσημο tutorial (και notebook) του\n",
    "TensorFlow [\"Image captioning with visual\n",
    "attention\"](https://www.TensorFlow.org/tutorials/text/image_captioning).\n",
    "Θα δουλέψουμε ωστόσο σε άλλο dataset και θα προσπαθήσουμε να βελτιώσουμε\n",
    "το tutorial σε διάφορα σημεία.\n",
    "\n",
    "Τέλος, θα υπάρχει προαιρετικά η δυνατότητα υποβολής προβλέψεων πάνω σε\n",
    "δεδομένα ελέγχου χωρίς λεκτικές περιγραφές για τη συμμετοχή σε ένα μικρό\n",
    "in-class competition χωρίς καμία βαθμολογική σημασία.\n",
    "\n",
    "![](attachment:vertopal_bfcea80d13ad40e58ffd03b8a181b5eb/a97193fd953c58d5a304dab68d9ae0f5b8a81ef7.jpg)\n",
    "\n",
    "Ανοίξτε το notebook στο Colab ώστε να βλέπετε όλα τα κελιά. Στο web\n",
    "version χρειάζεται να κάνετε \"Toggle code\" και \"Toggle section\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Σύνολο δεδομένων\n",
    "\n",
    "Τα ευρύτερα χρησιμοποιούμενα datasets στο Image Captioning είναι τα\n",
    "Flickr8k, Flickr30k, και το COCO. Το παράδειγμα του TensorFlow\n",
    "χρησιμοποιεί το Flickr8k και το Conceptual Captions. Εμείς θα\n",
    "χρησιμοποιήσουμε το \"flickr30k-images-ecemod\", ένα split του Flick30k\n",
    "ειδικά για το μάθημά μας.\n",
    "\n",
    "Τα δεδομένα του flickr30k-images-ecemod είναι τα εξής:\n",
    "\n",
    "-   ένας φάκελος \"image_dir\" με 31.783 εικόνες από το Flickr\n",
    "-   ένα αρχείο \"captions_new.csv\" με 148.915 captions για τις εικόνες\n",
    "    του \"image_dir\"\n",
    "-   ένα αρχείο \"train_files.csv\" λίστα των 21.000 εικόνων που αποτελούν\n",
    "    το training set\n",
    "-   ένα αρχείο \"test_files.csv\" λίστα των 4.524 εικόνων που αποτελούν το\n",
    "    test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Εποπτεία των δεδομένων\n",
    "\n",
    "To flickr30k-images-ecemod έχει παρόμοια οργάνωση με το COCO. Κάθε\n",
    "εικόνα έχει 5 captions που έχουν γίνει από διαφορετικούς ανθρώπους μέσω\n",
    "της υπηρεσίας Mechanical Turk της Amazon. Ένα παράδειγμα:\n",
    "\n",
    "Παράδειγμα εικόνας: \\_100007487.jpg\n",
    "\n",
    "![\\_100007487.jpg](https://i.imgur.com/wyBuzfC.jpg)\n",
    "\n",
    "`_100007487.jpg#0  A young child walks down a gravel path lined with a row of red outdoor chairs .`\n",
    "\n",
    "`_100007487.jpg#1 A racetrack with red chairs stacked beside fence with a child walking .`\n",
    "\n",
    "`_100007487.jpg#2 A child in a striped shirt walks by some red chairs .`\n",
    "\n",
    "`_100007487.jpg#3   A child walking and leaving a trail behind them .`\n",
    "\n",
    "`_100007487.jpg#4   A little kid is walking next to red banners .`\n",
    "\n",
    "Κάθε caption έχει τρία πεδία, το όνομα του αρχείου της εικόνας, τον\n",
    "αύξοντα αριθμό του caption και τέλος το ίδιο το caption."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Κατέβασμα του συνόλου δεδομένων\n",
    "\n",
    "Με τον κώδικα που ακολουθεί, θα κατεβάσουμε το δικό μας dataset,\n",
    "αντικαθιστώντας τα sections \"Choose a dataset\" και \"Download the\n",
    "dataset\". Τα προηγούμενα κελιά με τα installations και imports πρέπει να\n",
    "τα τρέξετε.\n",
    "\n",
    "Στο επόμενο κελί κατεβάζουμε τις εικόνες του dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 1.12.0\n",
      "Uninstalling tensorflow-1.12.0:\n",
      "  Successfully uninstalled tensorflow-1.12.0\n",
      "\u001b[33mWARNING: Skipping estimator as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y tensorflow estimator keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_text\n",
      "  Downloading tensorflow_text-2.11.0-cp39-cp39-macosx_10_9_x86_64.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-macosx_10_14_x86_64.whl (244.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.8.1-py3-none-any.whl (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.8.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.24.1)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: packaging in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-macosx_10_9_x86_64.whl (980 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m980.5/980.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.3.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (63.4.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-macosx_10_9_x86_64.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_datasets) (8.0.4)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dill in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_datasets) (4.64.1)\n",
      "Collecting etils[enp,epath]>=0.9.0\n",
      "  Downloading etils-0.9.0-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: toml in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: psutil in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting importlib_resources\n",
      "  Downloading importlib_resources-5.10.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: zipp in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.9.24)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.0.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.0/177.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.3.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.57.1-py2.py3-none-any.whl (218 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.0/218.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/alex/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=4e81ab271e44c4229bfd429bd7ca05e5e650cc15141581eb1466e86aaa62bcfd\n",
      "  Stored in directory: /Users/alex/Library/Caches/pip/wheels/68/ee/8d/57af0d8b0d34c2e918ff29d3af02b348db6499bb107caa007e\n",
      "Successfully built promise\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, dm-tree, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, promise, opt-einsum, oauthlib, keras, importlib_resources, google-pasta, gast, etils, cachetools, astunparse, tensorflow-hub, requests-oauthlib, googleapis-common-protos, google-auth, tensorflow-metadata, google-auth-oauthlib, tensorflow_datasets, tensorboard, tensorflow, tensorflow_text\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.12.2\n",
      "    Uninstalling tensorboard-1.12.2:\n",
      "      Successfully uninstalled tensorboard-1.12.2\n",
      "Successfully installed astunparse-1.6.3 cachetools-5.2.0 dm-tree-0.1.8 etils-0.9.0 flatbuffers-23.1.4 gast-0.4.0 google-auth-2.15.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.57.1 importlib_resources-5.10.2 keras-2.11.0 libclang-14.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 promise-2.3 protobuf-3.19.6 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-hub-0.12.0 tensorflow-io-gcs-filesystem-0.29.0 tensorflow-metadata-1.12.0 tensorflow_datasets-4.8.1 tensorflow_text-2.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U tensorflow_text tensorflow tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m477.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import collections\n",
    "import dataclasses\n",
    "import hashlib\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Download image files\n",
    "image_zip = tf.keras.utils.get_file('flickr30k-images-ecemod.zip',\n",
    "                                      cache_subdir=os.path.abspath('.'),\n",
    "                                      origin='https://spartacus.1337.cx/flickr-mod/flickr30k-images-ecemod.zip',\n",
    "                                      extract=True)\n",
    "os.remove(image_zip)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "και με το επόμενο τα \"captions_new.csv\", \"train_files.csv\" και\n",
    "\"test_files.csv\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download captions file\n",
    "captions_file = tf.keras.utils.get_file('captions_new.csv',\n",
    "                                           cache_subdir=os.path.abspath('.'),\n",
    "                                           origin='https://spartacus.1337.cx/flickr-mod/captions_new.csv',\n",
    "                                           extract=False)\n",
    "\n",
    "# Download train files list\n",
    "train_files_list = tf.keras.utils.get_file('train_files.csv',\n",
    "                                           cache_subdir=os.path.abspath('.'),\n",
    "                                           origin='https://spartacus.1337.cx/flickr-mod/train_files.csv',\n",
    "                                           extract=False)\n",
    "\n",
    "# Download test files list\n",
    "test_files_list = tf.keras.utils.get_file('test_files.csv',\n",
    "                                           cache_subdir=os.path.abspath('.'),\n",
    "                                           origin='https://spartacus.1337.cx/flickr-mod/test_files.csv',\n",
    "                                           extract=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Με τον ακόλουθο κώδικα οργανώνουμε τα filenames και τα captions σε\n",
    "λίστες και ετοιμάζουμε τα train και test sets για το TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\".\"\n",
    "IMAGE_DIR=\"image_dir\"\n",
    "path = pathlib.Path(path)\n",
    "   \n",
    "captions = (path/captions_file).read_text().splitlines()\n",
    "captions = (line.split('\\t') for line in captions)\n",
    "captions = ((fname.split('#')[0], caption) for (fname, caption) in captions)\n",
    "   \n",
    "cap_dict = collections.defaultdict(list)\n",
    "for fname, cap in captions:\n",
    "  cap_dict[fname].append(cap)\n",
    "   \n",
    "train_files = (path/train_files_list).read_text().splitlines()\n",
    "train_captions = [(str(path/IMAGE_DIR/fname), cap_dict[fname]) for fname in train_files]\n",
    "   \n",
    "test_files = (path/test_files_list).read_text().splitlines()\n",
    "test_captions = [(str(path/IMAGE_DIR/fname), cap_dict[fname]) for fname in test_files]\n",
    "   \n",
    "train_raw = tf.data.experimental.from_list(train_captions)\n",
    "test_raw = tf.data.experimental.from_list(test_captions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μετά των κώδικα αυτό, μπορείτε να συνεχίσετε από το κελί"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.element_spec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "του παραδείγματος, δουλεύοντας πλέον με το δικό μας dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Drive mount (προαιρετικό)\n",
    "\n",
    "Επειδή το κατέβασμα των εικόνων παίρνει κάποια λεπτά μια καλή ιδέα θα\n",
    "ήταν να τις έχετε μόνιμα σε ένα directory στο Google Drive που θα κάνετε\n",
    "mount μέσα στο notebook.\n",
    "\n",
    "1.  Φτιάξτε ένα καινούριο λογαριασμό Gmail για να έχετε χώρο.\n",
    "\n",
    "2.  Κατεβάστε τις εικόνες, κάντε τες unzip και ανεβάστε το folder\n",
    "    \"image_dir\" στο Google Drive.\n",
    "\n",
    "3.  Εντός του notebook, χρησιμοποιείστε το button στο αριστερό sidebar\n",
    "    για να εισάγετε τον κώδικα που χρειάζεται να τρέξετε για να κάνει\n",
    "    mount το Google Drive. To Drive θα εμφανιστεί στο sidebar αν κάνετε\n",
    "    ένα refresh. Με hover πάνω στα αρχεία και τους φακέλους, εμφανίζεται\n",
    "    ένα hamburger button που σας επιτρέπει να αντιγράψετε το path τους.\n",
    "\n",
    "    Google Drive mount\n",
    "\n",
    "    ![](https://i.imgur.com/SRJYKUQ.jpg)\n",
    "\n",
    "4.  Αν το \"image_dir\" είναι στο root του Drive τότε μπορείτε να\n",
    "    τροποποιήσετε τις προηγούμενες μεταβλητές `train_captions` και\n",
    "    `test_captions` ως εξής:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pathlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rz/x38ry1m901jcjct47ydtrgph0000gn/T/ipykernel_9027/3458554606.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_captions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mIMAGE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_captions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mIMAGE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pathlib' is not defined"
     ]
    }
   ],
   "source": [
    "new_path = '/content/drive/MyDrive'\n",
    "new_path = pathlib.Path(new_path)\n",
    "\n",
    "train_captions = [(str(new_path/IMAGE_DIR/fname), cap_dict[fname]) for fname in train_files]\n",
    "test_captions = [(str(new_path/IMAGE_DIR/fname), cap_dict[fname]) for fname in test_files]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Πλέον θα αρκεί να είναι mounted το Drive για να μπορούμε να\n",
    "διαβάσουμε τις εικόνες. Παρόμοια μπορείτε αν θέλετε να κάνετε και\n",
    "για τα υπόλοιπα αρχεία."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Το μοντέλο\n",
    "\n",
    "To μοντέλο βασίζεται στην γενική αρχιτεκτονική των μετασχηματιστών. Ένα\n",
    "συνελικτικό δίκτυο χρησιμοποιείται ως encoder της οπτικής πληροφορίας\n",
    "και μια σειρά από επίπεδα transformer-decoder παράγουν την λεκτική\n",
    "περιγραφή. Τα επίπεδα του transformer-decoder περιλαμβάνουν και επίπεδα\n",
    "προσοχής (attention).\n",
    "\n",
    "Transformer-decoder architecture\n",
    "\n",
    "![](https://tensorflow.org/images/tutorials/transformer/ImageCaptioning.png)\n",
    "\n",
    "Για την εξοικείωσή σας με τις αρχιτεκτονικές αυτές μπορείτε να διαβάσετε\n",
    "τα tutorials του TensorFlow [Text\n",
    "generation](https://www.TensorFlow.org/text/tutorials/text_generation),\n",
    "[sequence-to-sequence](https://www.TensorFlow.org/text/tutorials/nmt_with_attention),\n",
    "και\n",
    "[Transformers](https://www.TensorFlow.org/text/tutorials/transformer).\n",
    "\n",
    "Στη συνέχεια μπορείτε να τρέξετε όλο το notebook για να δείτε τί κάνει\n",
    "συνολικά."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Αξιολόγηση της ποιότητας του captioning (BLEU)\n",
    "\n",
    "To tutorial δεν περιλαμβάνει κάποια αναφορά στην ποιότητα του\n",
    "παραγόμενου captioning. Αν θεωρήσουμε ότι κάθε εικόνα έχει κάποια\n",
    "αληθινά captions (references) και το νευρωνικό παράγει ένα δικό του\n",
    "caption (hypothesis) θα χρησιμοποιήσουμε τo BLEU (Bilingual Evaluation\n",
    "Understudy) score, μεταξύ hypothesis και references. Συνοπτικά, το BLEU\n",
    "είναι ένας σταθμισμένος μέσος όρος του πλήθους των κοινών unigrams,\n",
    "bigrams, trigrams, και fourgrams μεταξύ hypothesis και references. Το\n",
    "χειρότερο captioning λαμβάνει 0 και το καλύτερο 1. Δείτε ένα αναλυτικό\n",
    "παράδειγμα υπολογισμού του BLEU\n",
    "[εδώ](https://cloud.google.com/translate/automl/docs/evaluate).\n",
    "\n",
    "Για να παραχθεί ένα caption για μια εικόνα, πρώτα την φορτώνουμε με τη\n",
    "μέθοδο `image = load_image(image_path)` και στη συνέχεια καλούμε τη\n",
    "μέθοδο `model.simple_gen(image)`.\n",
    "\n",
    "Η NLTK στο\n",
    "[nltk.translate.bleu_score](https://www.nltk.org/_modules/nltk/translate/bleu_score.html)\n",
    "παρέχει τις απαραίτητες συναρτήσεις για τον υπολογισμό των BLEU scores:\n",
    "\n",
    "-   Για να μπορείτε να αξιολογείτε το captioning ενός μεμονωμένου\n",
    "    παραδείγματος φτιάξτε μια συνάρτηση που να υπολογίζει την\n",
    "    `sentence_bleu` μεταξύ hypothesis και αληθινών captions (references)\n",
    "    για μια εικόνα.\n",
    "-   Για να αξιολογείτε το captioning περισσότερων εικόνων πχ ενός μέρους\n",
    "    ή όλου του test set φτιάξτε συνάρτηση που θα υπολογίζει την\n",
    "    `corpus_bleu` μεταξύ όλων των hypotheses και references των εικόνων\n",
    "    που του δίνονται. Σημειώστε ότι το `corpus_bleu` δεν είναι μέσος\n",
    "    όρος των `sentence_bleu`.\n",
    "\n",
    "Σε όλες τις περιπτώσεις χρησιμοποιήστε τις εξής παραμέτρους:\n",
    "`weights=(0.4, 0.3, 0.2, 0.1)` και\n",
    "`smoothing_function=SmoothingFunction().method1`.\n",
    "\n",
    "Πριν τον υπολογισμό, αφαιρείτε πάντοτε από τα references την τελική\n",
    "τελεία (το τελευταίο στοιχείο της λίστας).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βελτιώσεις (και παραδοτέα)\n",
    "\n",
    "Το πρώτο παραδοτέο είναι οι συναρτήσεις για τα BLEU scores της\n",
    "προηγούμενης παραγράφου.\n",
    "\n",
    "Στη συνέχεια, εφόσον αποκτήσετε μια εικόνα της επίδοσης του default\n",
    "δικτύου (loss, accuracy, plots, χρόνοι εκπαίδευσης, BLEU scores) θα\n",
    "δοκιμάσουμε κάποιες ιδέες για βελτιώσεις στο δίκτυο (λοιπά παραδοτέα)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "Το παράδειγμα χρησιμοποιεί για encoder με μεταφορά μάθησης το\n",
    "MobileNetV3Small. Στα [έτοιμα\n",
    "μοντέλα](https://keras.io/api/applications/) CNN του Keras υπάρχουν\n",
    "μοντέλα που εμφανίζονται να έχουν καλύτερες benchmark επιδόσεις από το\n",
    "MobileNet (V2).\n",
    "\n",
    "Κρατήστε σταθερή τη διαδικασία train του decoder και δείτε αν μπορείτε\n",
    "να πάρετε καλύτερες επιδόσεις χρησιμοποιώντας άλλο συνελικτικό για\n",
    "encoder.\n",
    "\n",
    "Όταν καταλήξετε στον encoder μπορείτε να χρησιμοποιήσετε τη δυνατότητα\n",
    "caching των features που περιέχεται στο notebook ώστε να τα διαβάζετε /\n",
    "σώζετε από και προς το Drive αντί να τα παράγετε κάθε φορά."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Προεπεξεργασία κειμένου\n",
    "\n",
    "1.  Τα captions έχουν διαφορετικά μήκη. Ενδεχομένως τα πολύ σύντομα και\n",
    "    τα πολύ εκτενή να μην είναι χρήσιμα στην εκπαίδευση. Στο tutorial\n",
    "    χρησιμοποιείται ad-hoc ένα μέγιστο μήκος 50 λέξεων. Μπορείτε να\n",
    "    φιλτράρετε το dataset έτσι ώστε να έχετε ένα range από διαφορετικά\n",
    "    μήκη, χωρίς ούτε τα πολύ μικρά και χωρίς ούτε τα πολύ μεγάλα\n",
    "    (δοκιμάστε ένα ιστόγραμμα). Θα πρέπει να προσαρμόσετε αναλόγως και\n",
    "    την `max_length`.\n",
    "2.  Μελετήστε τα captions. Θα μπορούσε η συνάρτηση `standardize` να\n",
    "    περιλαμβάνει και άλλα φίλτρα κανονικοποίησης; Προσοχή, εδώ δεν\n",
    "    κάνουμε stemming.\n",
    "3.  To tutorial αποφασίζει ad hoc για ένα vocabulary 5000 λέξεων.\n",
    "    Δοκιμάστε και κάποια διαφορετικά (μικρότερα ή μεγαλύτερα) μεγέθη\n",
    "    vocabulary.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "Στο παράδειγμα του tutorial τα embeddings μαθαίνονται κατά την\n",
    "εκπαίδευση του μοντέλου. Αντί αυτού μπορούμε να χρησιμοποιήσουμε έτοιμα\n",
    "embeddings με μεταφορά μάθησης. Δείτε πώς αποδίδει το δίκτυο για\n",
    "παράδειγμα με τα embeddings glove-wiki του\n",
    "[Gensim](https://radimrehurek.com/gensim/models/word2vec.html) διαφόρων\n",
    "διαστάσεων (50, 100, 200, 300)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Generator (Beam Search)\n",
    "\n",
    "Στο παράδειγμα χρησιμοποείται η μεταβλητή της \"θερμοκρασίας\"\n",
    "(`temperature`) για να παράγονται οι προτάσεις. Αν η θερμοκρασία είναι\n",
    "0.0, έχουμε greedy decoding και επιλέγεται το πιο πιθανό token σε κάθε\n",
    "βήμα. Αν η θερμοκρασία είναι 1.0 κάνει τυχαίο sampling ως προς τις\n",
    "πιθανότητες (logits) του κάθε token. Αν η θερμοκρασία είναι πολύ\n",
    "μεγαλύτερη του 1.0 καταλήγουμε σε ομοιόμορφο τυχαίο sampling.\n",
    "\n",
    "Beam Search sentence generation\n",
    "\n",
    "![](https://miro.medium.com/max/2400/1*tEjhWqUgjX37VnT7gJN-4g.png)\n",
    "\n",
    "Στη βιβλιογραφία ωστόσο αναφέρεται ότι η μέθοδος [Beam\n",
    "Search](https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24)\n",
    "παράγει σημαντικά καλύτερα αποτελέσματα. H Beam Search έχει μια\n",
    "υπερπαράμετρο που είναι το πλάτος της ακτίνας b. Για να διαλέξει την\n",
    "επόμενη λέξη ξεκινάει από την αρχή της πρότασης `[START]` και κρατάει\n",
    "τις b to πλήθος καλύτερες (πιθανότερες) λέξεις για το επόμενο βήμα. Με\n",
    "τον τρόπο αυτό δημιουργούντα b κλαδιά. Για το επόμενο βήμα υπολογίζει\n",
    "τις πιθανότητες των επόμενων λέξεων για όλα τα κλαδιά και κρατάει τις b\n",
    "πιθανότερες κοκ. Στο τέλος `[END]` καταλήγουμε να έχουμε b πιθανές\n",
    "προτάσεις και διαλέγουμε αυτή με τις καλύτερες πιθανότητες συνολικά. Για\n",
    "το τελευταίο, θα μπορούσαμε για παράδειγμα να χρησιμοποιήσουμε το Σ του\n",
    "log των πιθανοτήτων δια του μήκους της κάθε πρότασης.\n",
    "\n",
    "Θα βρείτε στο διαδίκτυο έτοιμες υλοποιήσεις για το Beam Search που\n",
    "μπορείτε να προσαρμόσετε, όπως επίσης και συνήθεις τιμές για το b.\n",
    "Μπορείτε να τροποποιήσετε τα ορίσματα της `simple_gen` ώστε να καλύπτει\n",
    "και το Beam Search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Υπερπαράμετροι του decoder\n",
    "\n",
    "Μελετήστε την επίδραση των υπερπαραμέτρων `units`, `dropout_rate`,\n",
    "`num_layers`, και `num_heads` του μοντέλου.\n",
    "\n",
    "Οι χρόνοι εκπαίδευσης μπορεί να είναι σημαντικοί. Χρησιμοποιήστε κάποια\n",
    "[μέθοδο αποθήκευσης του\n",
    "μοντέλου](https://www.TensorFlow.org/tutorials/keras/save_and_load) ώστε\n",
    "να μπορείτε να συνεχίζετε την εκπαίδευση.\n",
    "\n",
    "Προφανώς δεν μπορούμε να κάνουμε cross-validation των παραμέτρων και\n",
    "αρχιτεκτονικών. Χρησιμοποιείτε σταδιακό training (σχετικά λίγα epochs)\n",
    "και εκτίμηση της απόδοσης του δικτύου με βάση το loss και τον\n",
    "απαιτούμενο χρόνο, ενώ παράλληλα εξετάζετε την ποιότητα του captioning\n",
    "με την `sentence_bleu` για επιλεγμένες εικόνες και κυρίως την\n",
    "`corpus_bleu` για ένα κομμάτι του test set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Παραδοτέο\n",
    "\n",
    "Το notebook με το καλύτερο μοντέλο σας ως προς το `corpus_bleu` σε\n",
    "τουλάχιστον 1000 εικόνες από το test set. Μπορείτε να δοκιμάσετε και σε\n",
    "περισσότερες εικόνες, ιδανικά σε όλο το test set, απλά είναι θέμα χρόνου\n",
    "η παραγωγή των captions.\n",
    "\n",
    "Χρησιμοποιήστε markdown για να εξηγήσετε τις επιλογές σας. Μπορείτε να\n",
    "σημειώσετε τιμές του BLEU και για ενδιάμεσες επιλογές και να τις\n",
    "παρουσιάσετε σε πίνακα. Δώστε παραδείγματα εικόνων με επιτυχημένα και\n",
    "λιγότερο επιτυχημένα captioning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Διαγωνισμός (προαιρετικός)\n",
    "\n",
    "Η συμμετοχή στο διαγωνισμό είναι προαιρετική και δεν έχει καμία\n",
    "βαθμολογική σημασία. Ωστόσο, επειδή η κατάταξη γίνεται με βάση το\n",
    "`corpus_bleu`, η συμμετοχή και σύγκριση με άλλες υποβολές μπορεί να σας\n",
    "δείχνει πόσο έχετε προχωρήσει στη βελτίωση των captions σας."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εικόνες διαγωνισμού\n",
    "\n",
    "Για τον διαγωνισμό έχουμε επιλέξει 500 εικόνες για τις οποίες δεν έχετε\n",
    "καθόλου captions. Τα ονόματά τους περιλαμβάνονται στο\n",
    "\"competition_files.csv\". Μπορείτε να τις διαβάσετε με τον ακόλουθο\n",
    "κώδικα:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download competition files list\n",
    "competition_files_list = tf.keras.utils.get_file('competition_files.csv',\n",
    "                                           cache_subdir=os.path.abspath('.'),\n",
    "                                           origin='https://spartacus.1337.cx/flickr-mod/competition_files.csv',\n",
    "                                           extract=False)\n",
    "\n",
    "path=\".\"\n",
    "IMAGE_DIR=\"image_dir\"\n",
    "path = pathlib.Path(path)\n",
    "\n",
    "competition_files = (path/competition_files_list).read_text().splitlines()\n",
    "competition_files = [str(path/IMAGE_DIR/fname) for fname in competition_files]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μην ξεχάσετε να αλλάξετε τα paths για τα αρχεία των εικόνων αν\n",
    "χρησιμοποιείτε το Google Drive."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Δημιουργία αρχείου υποβολής\n",
    "\n",
    "Για όλες τις εικόνες του \"competition_files.csv\" και με την σειρά που\n",
    "έχουν οι εικόνες (κάνοντας append δηλαδή) δημιουργήστε captions με τη\n",
    "μορφή λιστών. Αν ας πούμε είχαμε δύο εικόνες θα αποθηκεύαμε σε μια\n",
    "μεταβλητή `test_hypotheses` τα captions ως εξής:\n",
    "\n",
    "`[['a',  'woman',  'floats',  'with',  'her',  'face',  'out',  'of',  'water',  'in',  'a',  'pool',  'with',  'another',  'woman',  'nearby',  'posing',  'for',  'the',  'camera'], ['a', 'black', 'and', 'white', 'dog', 'walks', 'along', 'a', 'sandy', 'beach']]`\n",
    "\n",
    "Υπολογίστε τα 500 captions στη μεταβλητή test_hypotheses και αποθηκεύετε\n",
    "την ως JSON ως εξής:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "jsonString = json.dumps(test_hypotheses)\n",
    "jsonFile = open(\"test_hypotheses.json\", \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κατεβάζετε τοπικά το αρχείο test_ypotheses.json, <u>το μετονομάζετε\n",
    "υποχρεωτικά σε answer.txt και το zipάρετε σε zip file</u> το όνομα του\n",
    "οποίου δεν έχει σημασία.\n",
    "\n",
    "Συνημμένο στην εκφώνηση θα βρείτε ένα παράδειγμα λειτουργικού\n",
    "[answer.txt](https://helios.ntua.gr/pluginfile.php/179077/mod_assign/introattachment/0/answer.txt?forcedownload=1)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Το site του διαγωνισμού στο Codalab\n",
    "\n",
    "![\\[Codalab\n",
    "competition\\](https://codalab.lisn.upsaclay.fr/competitions/926)](https://i.imgur.com/0fvamAe.png)\n",
    "\n",
    "Ο διαγωνισμός βρίσκεται στο [σύνδεσμο αυτό προς το\n",
    "Codalab](https://codalab.lisn.upsaclay.fr/competitions/926).\n",
    "Χρησιμοποιήθηκε το Codalab αντί του Kaggle γιατί το Kaggle στο community\n",
    "tier δεν επιτρέπει custom μετρικές όπως η BLEU. To Codalab είναι επίσης\n",
    "το επίσημο αποθετήριο του COCO.\n",
    "\n",
    "Θα πρέπει να κάνετε register. Σημειώστε ότι αν πάτε στα settings στο\n",
    "profile σας μπορείτε να ορίσετε όνομα ομάδας και μέλη της με τα username\n",
    "όλων σας στο Codalab. Προφανώς το όνομα της ομάδας μπορεί να είναι ό,τι\n",
    "θέλετε, άσχετο με τον αριθμό στο εργαστήριο."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Υποβολή απάντησης και leaderboard\n",
    "\n",
    "Προκειμένου να ανεβάσετε μια απάντηση, θα πρέπει να πάτε στο tab\n",
    "\"Participate\", στο \"Submit/View Results\" και να πατήσετε \"Submit\" για να\n",
    "ανεβάσετε το αρχείο υποβολής. Μπορείτε να κάνετε refresh της κατάστασης\n",
    "της υποβολής μέσω του διαθέσιμου button \"Refresh Status\". Όταν η υποβολή\n",
    "ολοκληρωθεί, και εφόσον είναι έγκυρη, κάντε refresh την σελίδα μέσω του\n",
    "browser για να δείτε το score σας. Εάν το score σας σας ικανοποιεί,\n",
    "μπορείτε να κάνετε \"Submit to leaderboard\".\n",
    "\n",
    "Στο tab \"Results\" θα βρείτε το leaderboard των submissions όλων των\n",
    "ομάδων με βάση το `corpus_bleu`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "472f3460692ba2c0861145e5e150d03c8a5c0e40e057944a047c431b9050b93d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
